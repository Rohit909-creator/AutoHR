# from llama_index.embeddings.ollama import OllamaEmbedding
# import torch
# ollama_embedding = OllamaEmbedding(
#     model_name="nomic-embed-text",
#     base_url="http://localhost:11434",
#     ollama_additional_kwargs={"mirostat": 0},
# )

# pass_embedding = ollama_embedding.get_text_embedding_batch(
#     ["Where is Blue? is a book by Bibi Farooq that helps children learn sight words. The book is intended for children aged 4-6 and is about a boy looking for a lost toy in his room. ", "Red is a color that can be found in many places, including the visible spectrum of light, in paint, and in nature. ", "Dogs are domesticated mammals that are known for their loyalty and companionship. They are often called 'man's best friend. "],
#     show_progress=True
# )
# # print(len(pass_embedding))
# pass_embedding_t = torch.tensor(pass_embedding)
# query_embedding = ollama_embedding.get_query_embedding("Where is blue?")
# # print(len(query_embedding))

# query_embedding_t = torch.tensor(query_embedding)

# out = torch.cosine_similarity(query_embedding_t, pass_embedding_t)
# print(out)
# # torch.cosine_similarity()





# import ollama
# import time
# # Your input text
# input_text = "Hello, how are you today?"

# # Generate a response
# start = time.time()
# response = ollama.generate(model="llama2", prompt=input_text)
# end = time.time()
# print(f"Generated response {end-start}: {response['response']}")

# start = time.time()
# input_text = "Write a python code for prompting a message on a window on the system when executed"
# response = ollama.generate(model="llama2", prompt=input_text)
# end = time.time()
# print(f"Generated response {end-start}: {response['response']}")

# import uuid


# employee_data = {
#     "Software Developers": [
#         {
#             "name": "Alice Johnson",
#             "role": "Full Stack Developer",
#             "skills": ["Python", "React", "Django"],
#             "experience_years": 3,
#             "busy_level": "low",            # low, medium, high
#             "can_multi_task": True,
#             "quick_learner": True
#         },
#         {
#             "name": "Bob Smith",
#             "role": "Backend Developer",
#             "skills": ["Java", "Spring Boot", "SQL"],
#             "experience_years": 5,
#             "busy_level": "medium",
#             "can_multi_task": False,
#             "quick_learner": False
#         },
#         {
#             "name": "Charlie Kim",
#             "role": "Frontend Developer",
#             "skills": ["HTML", "CSS", "JavaScript", "React"],
#             "experience_years": 2,
#             "busy_level": "high",
#             "can_multi_task": True,
#             "quick_learner": True
#         }
#     ],
#     "AI/ML Engineers": [
#         {
#             "name": "Dana Lee",
#             "role": "Data Scientist",
#             "skills": ["Python", "TensorFlow", "Pandas"],
#             "experience_years": 4,
#             "busy_level": "medium",
#             "can_multi_task": True,
#             "quick_learner": True
#         },
#         {
#             "name": "Evan Wu",
#             "role": "ML Engineer",
#             "skills": ["Python", "PyTorch", "scikit-learn"],
#             "experience_years": 2,
#             "busy_level": "low",
#             "can_multi_task": True,
#             "quick_learner": True
#         },
#         {
#             "name": "Fiona Zhang",
#             "role": "Research Scientist",
#             "skills": ["Python", "Deep Learning", "NLP"],
#             "experience_years": 6,
#             "busy_level": "high",
#             "can_multi_task": False,
#             "quick_learner": True
#         }
#     ],
#     "Project Managers": [
#         {
#             "name": "George Martin",
#             "role": "Senior Project Manager",
#             "skills": ["Agile", "Scrum", "Leadership"],
#             "experience_years": 7,
#             "busy_level": "medium",
#             "can_multi_task": True,
#             "quick_learner": False
#         },
#         {
#             "name": "Hannah Davis",
#             "role": "Project Manager",
#             "skills": ["Kanban", "Communication", "Team Coordination"],
#             "experience_years": 3,
#             "busy_level": "low",
#             "can_multi_task": True,
#             "quick_learner": True
#         }
#     ],
#     "QA Engineers": [
#         {
#             "name": "Ian Thompson",
#             "role": "Automation QA",
#             "skills": ["Selenium", "Python", "Testing"],
#             "experience_years": 4,
#             "busy_level": "medium",
#             "can_multi_task": False,
#             "quick_learner": True
#         },
#         {
#             "name": "Jasmine Patel",
#             "role": "Manual QA",
#             "skills": ["Testing", "Bug Reporting"],
#             "experience_years": 2,
#             "busy_level": "low",
#             "can_multi_task": True,
#             "quick_learner": True
#         }
#     ],
#     "DevOps": [
#         {
#             "name": "Kevin Brown",
#             "role": "DevOps Engineer",
#             "skills": ["AWS", "Docker", "Kubernetes"],
#             "experience_years": 5,
#             "busy_level": "medium",
#             "can_multi_task": True,
#             "quick_learner": False
#         },
#         {
#             "name": "Liam Chen",
#             "role": "Site Reliability Engineer",
#             "skills": ["GCP", "Terraform", "Monitoring"],
#             "experience_years": 3,
#             "busy_level": "low",
#             "can_multi_task": True,
#             "quick_learner": True
#         }
#     ]
# }


# def generate_employee_text_data(employee_data):
#     employee_dict = {}
    
#     for category, employees in employee_data.items():
#         for employee in employees:
#             employee_id = str(uuid.uuid4())  # Generate a unique ID for each employee
            
#             details = (
#                 f"Name: {employee['name']}, "
#                 f"Role: {employee['role']}, "
#                 f"Department: {category}, "
#                 f"Skills: {', '.join(employee['skills'])}, "
#                 f"Experience: {employee['experience_years']} years, "
#                 f"Busy Level: {employee['busy_level']}, "
#                 f"Can Multi-task: {'Yes' if employee['can_multi_task'] else 'No'}, "
#                 f"Quick Learner: {'Yes' if employee['quick_learner'] else 'No'}"
#             )
            
#             employee_dict[employee_id] = details
    
#     return employee_dict

# # Example usage
# employee_data_with_ids = generate_employee_text_data(employee_data)
# print(employee_data_with_ids.keys())
# print(employee_data_with_ids[list(employee_data_with_ids.keys())[0]])
# for emp_id, details in employee_data_with_ids.items():
#     print(f"ID: {emp_id}\nDetails: {details}\n")


# import ollama

# response = ollama.embed(model="nomic-embed-text", input=['Software Developers', 'AI/ML Engineers', 'Project Managers', 'QA Engineers', 'DevOps'])
# print(response['embeddings'])
# print(response)

# import json
# employee_data = {
#     "Junior web developers":[],
#     "Senior web developers":[],
#     "Junior AI Engineer": [],
#     "Project Leads":[],
#     "Project Managers":[],
#     "Marketing":[]
# }

# allocation_data = {
#     "AI Projects":[],
#     "Web Projects":[]
# }


# from groq import Groq

# client = Groq()
# completion = client.chat.completions.create(
#     model="llama-3.3-70b-versatile",
#     messages=[
#         {
#             "role": "system",
#             "content": "You are an AI HR, your task is to allocate workers to projects and tasks based on there skills, expertise etc.\nNot only that you can also plan to train some workers to do a specific task for which there are no experts available at the moment.\n\nWorker Data:\n\nRon: (Web Developer: Highly Expert) Two years in the company\nDon: (Junio Web Developer) fresher\nJohn: (Python Developer) fresher\nCarol: (Product lead) two years in the company\n\nAllocation Data:\nRon is already working in a project for company websites major bug fixes\nCarol is working on a small scale work of leading the team that Ron is in\n\nOutput format should be like,\nOptimal(<name>):<description>\nSuggestion(<name>):<description>\n"
#         },
#         {
#             "role": "user",
#             "content": "I need web developers for making a site for hospital, its just a simple one so, I think I won't need that much of expertise, suggest picks"
#         },
#         {
#             "role": "assistant",
#             "content": "Optimal(Don): Don, as a junior web developer, can handle a simple website project for a hospital, and it would be a good opportunity for him to gain experience and develop his skills.\nSuggestion(Ron): Although Ron is already working on a project, if the hospital website project is urgent and requires high-quality output, Ron's expertise as a highly experienced web developer could be utilized, but it would depend on his current workload and availability.\nSuggestion(Train John): If Don is not available or if you want to have another option, John, who is a Python developer, could be trained to work on web development for the hospital website project, as Python is often used in web development, and with some training, John could learn the necessary skills to handle a simple website project."
#         }
#     ],
#     temperature=1,
#     max_tokens=1024,
#     top_p=1,
#     stream=True,
#     stop=None,
# )

# for chunk in completion:
#     print(chunk.choices[0].delta.content or "", end="")
